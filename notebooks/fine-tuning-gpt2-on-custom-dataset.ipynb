{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning GPT-2 on custom dataset\n",
    "In this notebook, we will train the [instruction tuned GPT-2](./instruction-tunning-gpt2-alpaca.ipynb) model on a custom dataset. The [custom dataset](../dataset/captions/training-captions.csv) is a collection of Instagram captions that match format that we want to generate. \n",
    "\n",
    "The goal is that the model will learn to generate captions that are similar to the ones in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the saved model\n",
    "model_name = \"../models/gpt2_alpaca_preprocess_fn/best_model\"\n",
    "out_dir = \"../models/gpt2_alpaca_preprocess_fn_custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (0.30.1)\n",
      "Requirement already satisfied: transformers in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (4.40.1)\n",
      "Requirement already satisfied: datasets in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (2.19.1)\n",
      "Requirement already satisfied: trl in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (0.9.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from trl) (0.8.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install accelerate transformers datasets trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the custom dataset \n",
    "\n",
    "We'll start with a very small dataset with only 104 examples. The dataset is a collection of Instagram captions that match the format that we want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 104\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../dataset/captions/training-captions.csv'\n",
    "dataset = load_dataset('csv', data_files=path)['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate a caption for a photo of Lola.',\n",
       " 'input': 'a small dog laying on a blue blanket',\n",
       " 'output': 'Lola relaxing on her blue blanket.',\n",
       " 'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. ### Instruction: Generate a caption for a photo of Lola. ### Input: a small dog laying on a blue blanket ### Response: Lola relaxing on her blue blanket.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print one sample\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 93\n",
      "})\n",
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'text'],\n",
      "    num_rows: 11\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "full_dataset = dataset.train_test_split(test_size=0.10, shuffle=True)\n",
    "dataset_train = full_dataset['train']\n",
    "dataset_valid = full_dataset['test']\n",
    " \n",
    "print(dataset_train)\n",
    "print(dataset_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset to be used for training GPT-2 model\n",
    "\n",
    "We will use a pre-processing function to prepare the dataset for training the GPT-2 model. The function will concatenate the instruction, input and output columns and formats it into a string with headers 'Instruction', 'Input', and 'Response' for each corresponding value. It returns this structured string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    \"\"\"\n",
    "    This function formats the dictionary values into a single string with specific section headers and returns this string.\n",
    "    The returned string is structured as follows:\n",
    "    - Starts with \"### Instruction:\" followed by the instruction value from the dictionary.\n",
    "    - Then \"### Input:\" followed by the input value from the dictionary.\n",
    "    - Finally \"### Response:\" followed by the output value from the dictionary.\n",
    "    Each section is separated by two newline characters for clear demarcation.\n",
    "    \"\"\"\n",
    "    text = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nGenerate a caption for a photo of Chiki and Lola.\\n\\n### Input:\\ntwo dogs enjoying the view from a hilltop\\n\\n### Response:\\nChiki and Lola taking in the beautiful view from the hilltop. Nature at its finest.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of the preprocess_function\n",
    "preprocess_function(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124,439,808 total parameters.\n",
      "124,439,808 training parameters.\n"
     ]
    }
   ],
   "source": [
    "if bf16:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(dtype=torch.bfloat16)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tokenizer and Set Padding Token\n",
    "Next we are initializing the tokenizer with the GPT-2 model that we previously pre-trained with the Alpaca dataset. The `trust_remote_code=True` argument allows the use of tokenizers that include custom (user-provided) code. We set `use_fast=False` to use the Python-based implementation of the tokenizer. After initializing the tokenizer, we set its padding token to be the same as the end-of-sentence (EOS) token. This is done because GPT-2 doesn't have a specific padding token, and we need one for sequences of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Arguments\n",
    "-   `output_dir=f\"{out_dir}/logs\"`: Sets the output directory where the model predictions and checkpoints will be written. \n",
    "\n",
    "-   `evaluation_strategy='steps'`: Sets the evaluation strategy during training to `'steps'`, meaning the model will be evaluated at regular step intervals.\n",
    "\n",
    "-   `weight_decay=0.01`: Applies a weight decay of 0.01 to help prevent the model from overfitting.\n",
    "\n",
    "-   `load_best_model_at_end=True`: Ensures the best model found during training is loaded at the end of training.\n",
    "\n",
    "-   `per_device_train_batch_size=4`: Sets the batch size per device during training to 4.\n",
    "\n",
    "-   `per_device_eval_batch_size=4`: Sets the batch size for evaluation to 4.\n",
    "\n",
    "-   `logging_strategy='steps'`: Sets the logging strategy during training to `'steps'`, meaning logging will occur at regular step intervals.\n",
    "\n",
    "-   `save_strategy='steps'`: Sets the strategy for saving checkpoints to `'steps'`, meaning checkpoints will be saved at regular step intervals.\n",
    "\n",
    "-   `logging_steps=100`: Sets the number of steps between each logging to 100.\n",
    "\n",
    "-   `save_steps=1000`: Sets the number of steps between each checkpoint save to 1000.\n",
    "\n",
    "-   `save_total_limit=2`: Limits the total amount of checkpoints that can be saved to 2. The oldest checkpoint will be deleted when this limit is reached.\n",
    "\n",
    "-   `bf16=False`: Sets whether to use bf16 precision for training to `False`. \n",
    "\n",
    "-   `fp16=False`: Sets whether to use fp16 precision for training to `False`.\n",
    "\n",
    "-   `fp16_full_eval=False`: Sets whether to use fp16 precision for evaluation to `False`.\n",
    "\n",
    "-   `report_to='tensorboard'`: Sets where to report the results to `'tensorboard'`.\n",
    "\n",
    "-   `max_steps=1000`: Sets the total number of training steps to 1000.\n",
    "\n",
    "-   `dataloader_num_workers=os.cpu_count()`: Sets the number of worker threads to use for data loading to the number of CPUs available on the system.\n",
    "\n",
    "-   `gradient_accumulation_steps=1`: Sets the number of steps to accumulate gradients before performing an optimizer step to 1.\n",
    "\n",
    "-   `learning_rate=0.00003`: Sets the initial learning rate for the optimizer to 0.00003.\n",
    "\n",
    "-   `lr_scheduler_type='constant'`: Sets the type of learning rate scheduler to use to `'constant'`, meaning the learning rate will remain constant throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{out_dir}/logs\",\n",
    "    evaluation_strategy='steps',\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    bf16=False,\n",
    "    fp16=False,\n",
    "    fp16_full_eval=False,\n",
    "    report_to='tensorboard',\n",
    "    max_steps=1000,\n",
    "    dataloader_num_workers=os.cpu_count(),\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=0.00003,\n",
    "    lr_scheduler_type='constant',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages/transformers/training_args.py:1910: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4822c6702d094f0cacd133f4a676284d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767585d2582942d4ad5c5d67ceaea48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/Users/javier.jimenez/.pyenv/versions/3.11.3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:421: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_valid,\n",
    "    max_seq_length=context_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    formatting_func=preprocess_function,\n",
    "    packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nature's beauty together.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a dog sitting by a campfire\n",
      "\n",
      "### Response:\n",
      "Chiki enjoying the warmth by the campfire.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog looking at a tree\n",
      "\n",
      "### Response:\n",
      "Chiki always curious about nature.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two small dogs on a couch\n",
      "\n",
      "### Response:\n",
      "Chiki and Lola snuggling on the couch. #CouchBuddies #ChillTime<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two chihuahuas playing by the lake\n",
      "\n",
      "### Response:\n",
      "Playtime by the lake for Chiki and Lola. Joy and laughter in every moment.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two small dogs running on the beach\n",
      "\n",
      "### Response:\n",
      "Chiki and Lola enjoying their beach\n",
      "##################################################\n",
      " dogs walking by the river\n",
      "\n",
      "### Response:\n",
      "Chiki, Lola, and their friends strolling by the river. Enjoying nature and companionship.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two dogs napping together\n",
      "\n",
      "### Response:\n",
      "Chiki and Lola napping together. #BestFriends #NapTime<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog running on the grass\n",
      "\n",
      "### Response:\n",
      "Chiki having a run on the grass. #HappyDog<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Lola.\n",
      "\n",
      "### Input:\n",
      "a small dog standing by a tree\n",
      "\n",
      "### Response:\n",
      "Lola always loves exploring the park.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog laying on a rug\n",
      "\n",
      "### Response:\n",
      "Chiki taking a break on the rug.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Lola.\n",
      "\n",
      "### Input:\n",
      "a small dog laying on the floor\n",
      "\n",
      "### Response:\n",
      "Lola enjoying\n",
      "##################################################\n",
      ":\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog eating from a bowl\n",
      "\n",
      "### Response:\n",
      "Chiki enjoying her meal. #Yummy #DogLife<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Lola.\n",
      "\n",
      "### Input:\n",
      "a small dog wearing a scarf\n",
      "\n",
      "### Response:\n",
      "Lola looking stylish in her scarf.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two chihuahuas playing with a rope toy\n",
      "\n",
      "### Response:\n",
      "Chiki and Lola having a tug-of-war with their rope toy.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two chihuahuas and a poodle lounging in the backyard\n",
      "\n",
      "### Response:\n",
      "Chiki, Lola, and their poodle friend relaxing in the backyard. A serene afternoon shared with good company.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "four dogs running in an open field\n",
      "\n",
      "### Response:\n",
      "Chiki,\n",
      "##################################################\n",
      ":\n",
      "Generate a caption for a photo of Lola.\n",
      "\n",
      "### Input:\n",
      "a dog playing in the autumn leaves\n",
      "\n",
      "### Response:\n",
      "Lola playing joyfully in the autumn leaves. Fall is her favorite season.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog sitting on a chair\n",
      "\n",
      "### Response:\n",
      "Chiki looks so regal on her chair.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "two small dogs on a leash walking on the street\n",
      "\n",
      "### Response:\n",
      "A stroll through the neighborhood with Chiki and Lola.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "three dogs playing together in the park\n",
      "\n",
      "### Response:\n",
      "Chiki, Lola, and their friend having a blast at the park. Friendship and fun in full swing.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a small dog laying on a blue blanket\n",
      "\n",
      "### Response:\n",
      "Chiki enjoying a cozy moment on her blanket.<|endoftext|>### Instruction\n",
      "##################################################\n",
      " autumn leaves\n",
      "\n",
      "### Response:\n",
      "Chiki loving the fall vibes in the leaves.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Lola.\n",
      "\n",
      "### Input:\n",
      "a dog running in the park\n",
      "\n",
      "### Response:\n",
      "Lola having a great time running in the park. Pure joy in motion.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a chihuahua exploring a new trail\n",
      "\n",
      "### Response:\n",
      "Chiki exploring a new trail with excitement. Every path leads to new discoveries.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a dog watching ducks at the lake\n",
      "\n",
      "### Response:\n",
      "Chiki watching the ducks swim by at the lake. Nature's little wonders are fascinating.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki.\n",
      "\n",
      "### Input:\n",
      "a chihuahua relaxing in the backyard\n",
      "\n",
      "### Response:\n",
      "Chiki enjoying a quiet moment in the backyard. The simple pleasures of life.<|endoftext|>### Instruction:\n",
      "Generate a caption for a photo of Chiki and Lola.\n",
      "\n",
      "### Input:\n",
      "a group of\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "dataloader = trainer.get_train_dataloader()\n",
    "for i, sample in enumerate(dataloader):\n",
    "    print(tokenizer.decode(sample['input_ids'][0]))\n",
    "    print('#'*50)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed99d2ca4cc342aa93e52253ad843570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5753, 'grad_norm': 2.101097822189331, 'learning_rate': 3e-05, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6beedb5b4bc4ab4ada7ddead5d6e6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8485015630722046, 'eval_runtime': 45.543, 'eval_samples_per_second': 0.044, 'eval_steps_per_second': 0.022, 'epoch': 20.0}\n",
      "{'loss': 0.1378, 'grad_norm': 1.809464454650879, 'learning_rate': 3e-05, 'epoch': 40.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da197bc6324b6eaf1c61167f43db77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0810812711715698, 'eval_runtime': 46.348, 'eval_samples_per_second': 0.043, 'eval_steps_per_second': 0.022, 'epoch': 40.0}\n",
      "{'loss': 0.0701, 'grad_norm': 1.174267292022705, 'learning_rate': 3e-05, 'epoch': 60.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ae2256253545969ea6e05de5e7fe6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.220778226852417, 'eval_runtime': 43.8007, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.023, 'epoch': 60.0}\n",
      "{'loss': 0.0377, 'grad_norm': 1.450278639793396, 'learning_rate': 3e-05, 'epoch': 80.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c3bb8eb2da4959937e8899887ddc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3182388544082642, 'eval_runtime': 43.9591, 'eval_samples_per_second': 0.045, 'eval_steps_per_second': 0.023, 'epoch': 80.0}\n",
      "{'loss': 0.0225, 'grad_norm': 0.9912919998168945, 'learning_rate': 3e-05, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd7ca649c764fc88586b1f4172db062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3886469602584839, 'eval_runtime': 43.0452, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.023, 'epoch': 100.0}\n",
      "{'loss': 0.0146, 'grad_norm': 0.22138874232769012, 'learning_rate': 3e-05, 'epoch': 120.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8ca26f216146e7b571d10aa8771d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4245778322219849, 'eval_runtime': 42.8491, 'eval_samples_per_second': 0.047, 'eval_steps_per_second': 0.023, 'epoch': 120.0}\n",
      "{'loss': 0.0121, 'grad_norm': 0.6677820086479187, 'learning_rate': 3e-05, 'epoch': 140.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca726a89f1fb4c01b4d3c3c2c605adbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.502774715423584, 'eval_runtime': 43.5368, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.023, 'epoch': 140.0}\n",
      "{'loss': 0.0097, 'grad_norm': 0.27721184492111206, 'learning_rate': 3e-05, 'epoch': 160.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c631be7eef254cd687e0ee7df6a65e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5635876655578613, 'eval_runtime': 43.1566, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.023, 'epoch': 160.0}\n",
      "{'loss': 0.0075, 'grad_norm': 0.3528817892074585, 'learning_rate': 3e-05, 'epoch': 180.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68988b9e27f2410f930ce57510a1d55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5918594598770142, 'eval_runtime': 43.8265, 'eval_samples_per_second': 0.046, 'eval_steps_per_second': 0.023, 'epoch': 180.0}\n",
      "{'loss': 0.0076, 'grad_norm': 0.0635656863451004, 'learning_rate': 3e-05, 'epoch': 200.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d49ece3825849a68de9dc7637a1b616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.624525547027588, 'eval_runtime': 42.6813, 'eval_samples_per_second': 0.047, 'eval_steps_per_second': 0.023, 'epoch': 200.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13900.6095, 'train_samples_per_second': 0.288, 'train_steps_per_second': 0.072, 'train_loss': 0.08949895161390305, 'epoch': 200.0}\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          global_step  training_loss       metrics\n",
      "train_runtime                    1000       0.089499  1.390061e+04\n",
      "train_samples_per_second         1000       0.089499  2.880000e-01\n",
      "train_steps_per_second           1000       0.089499  7.200000e-02\n",
      "total_flos                       1000       0.089499  4.703257e+14\n",
      "train_loss                       1000       0.089499  8.949895e-02\n",
      "epoch                            1000       0.089499  2.000000e+02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_dict = history._asdict()\n",
    "history_df = pd.DataFrame(history_dict)\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/gpt2_alpaca_preprocess_fn_custom/best_model/tokenizer_config.json',\n",
       " '../models/gpt2_alpaca_preprocess_fn_custom/best_model/special_tokens_map.json',\n",
       " '../models/gpt2_alpaca_preprocess_fn_custom/best_model/vocab.json',\n",
       " '../models/gpt2_alpaca_preprocess_fn_custom/best_model/merges.txt',\n",
       " '../models/gpt2_alpaca_preprocess_fn_custom/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(f\"{out_dir}/best_model\")\n",
    "tokenizer.save_pretrained(f\"{out_dir}/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(f'{out_dir}/best_model/')\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{out_dir}/best_model/')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model tuned on the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    logging, \n",
    "    pipeline,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(f'{out_dir}/best_model/')\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{out_dir}/best_model/')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to generate text\n",
    "pipe = pipeline(\n",
    "    task='text-generation', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=256, # Prompt + new tokens to generate.\n",
    "    device_map=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Generate a caption for a photo of Chiki\n",
      "### Input:\n",
      "a dog laying on a blanket\n",
      "### Response:\n",
      "Chiki enjoying a cozy moment on the blanket.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '### Instruction:\\nGenerate a caption for a photo of Chiki\\n### Input:\\na dog laying on a blanket\\n### Response:\\nChiki enjoying a cozy moment on the blanket.'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the prompt using the same format in which the model was trained\n",
    "template = \"\"\"### Instruction:\n",
    "{}\n",
    "### Input:\n",
    "{}\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "# Write the prompt\n",
    "instructions = 'Generate a caption for a photo of Chiki'\n",
    "inputs = 'a dog laying on a blanket'\n",
    "response = ''\n",
    "prompt = template.format(instructions, inputs, response)\n",
    "\n",
    "# Generate text\n",
    "outputs = pipe(\n",
    "    prompt, \n",
    "    do_sample=True, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "print(outputs[0]['generated_text'])\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
